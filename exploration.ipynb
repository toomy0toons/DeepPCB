{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import seaborn as sns\n",
    "# PyTorch\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch\n",
    "from torch import optim, cuda\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "import torch.nn as nn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Data science tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Image manipulations\n",
    "from PIL import Image\n",
    "# Useful for examining network\n",
    "from torchsummary import summary\n",
    "# Timing utility\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# Printing out all outputs\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#datafolder setup\n",
    "datadir = 'AugData/'\n",
    "traindir = datadir + 'Train/train0217/'\n",
    "testdir = datadir + 'Test/test0217/'\n",
    "\n",
    "save_file_name = 'vgg16-0217.pt'\n",
    "checkpoint_path = 'vgg16-0217.pth'\n",
    "\n",
    "# config\n",
    "batch_size = 64\n",
    "train_on_gpu = cuda.is_available()\n",
    "print(train_on_gpu)\n",
    "\n",
    "# Number of gpus\n",
    "if train_on_gpu:\n",
    "    gpu_count = cuda.device_count()\n",
    "    print(gpu_count)\n",
    "    if gpu_count > 1:\n",
    "        multi_gpu = True\n",
    "    else:\n",
    "        multi_gpu = False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "categories = []\n",
    "img_categories = []\n",
    "n_train = []\n",
    "n_test = []\n",
    "\n",
    "# Iterate through each category\n",
    "for d in os.listdir(traindir):\n",
    "    categories.append(d)\n",
    "\n",
    "    # Number of each image\n",
    "    train_imgs = os.listdir(traindir + d)\n",
    "    test_imgs = os.listdir(testdir + d)\n",
    "    n_train.append(len(train_imgs))\n",
    "    n_test.append(len(test_imgs))\n",
    "\n",
    "    # Find stats for train images\n",
    "    for i in train_imgs:\n",
    "        img_categories.append(d)\n",
    "        img = Image.open(traindir + d + '/' + i)\n",
    "        img_array = np.array(img)\n",
    "\n",
    "# Dataframe of categories\n",
    "df = pd.DataFrame({'category': categories,\n",
    "                       'n_train': n_train, 'n_test': n_test}).\\\n",
    "    sort_values('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>copper</td>\n",
       "      <td>978</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mousebite</td>\n",
       "      <td>1332</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>open</td>\n",
       "      <td>1243</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pin_hole</td>\n",
       "      <td>998</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>short</td>\n",
       "      <td>988</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spur</td>\n",
       "      <td>1106</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category  n_train  n_test\n",
       "3     copper      978     447\n",
       "0  mousebite     1332     559\n",
       "5       open     1243     634\n",
       "1   pin_hole      998     449\n",
       "4      short      988     460\n",
       "2       spur     1106     463"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augentation\n",
    "\n",
    "image_transforms = {\n",
    "    #train is set to imagenet standard transform\n",
    "    'train':\n",
    "        transforms.Compose([\n",
    "        transforms.Resize(size=224),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    # no transform for test\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader\n",
    "\n",
    "data = {\n",
    "    'train':datasets.ImageFolder(root=traindir,transform=image_transforms['train']),\n",
    "    'test':datasets.ImageFolder(root=testdir,transform=image_transforms['test'])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True),\n",
    "    'test': DataLoader(data['test'], batch_size=batch_size, shuffle=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3, 224, 224]), torch.Size([64]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainiter = iter(dataloaders['train'])\n",
    "features,labels = next(trainiter)\n",
    "features.shape,labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(df)\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze early layers\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=6, bias=True)\n",
       "    (4): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_inputs = model.classifier[6].in_features\n",
    "\n",
    "# Add on classifier\n",
    "model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(0.4),\n",
    "    nn.Linear(256, n_classes), nn.LogSoftmax(dim=1))\n",
    "\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move to gpu\n",
    "if train_on_gpu:\n",
    "    model = model.to('cuda')\n",
    "\n",
    "if multi_gpu:\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_model(model_name):\n",
    "    \"\"\"Retrieve a pre-trained model from torchvision\n",
    "\n",
    "    Params\n",
    "    -------\n",
    "        model_name (str): name of the model (currently only accepts vgg16 and resnet50)\n",
    "\n",
    "    Return\n",
    "    --------\n",
    "        model (PyTorch model): cnn\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if model_name == 'vgg16':\n",
    "        model = models.vgg16(pretrained=True)\n",
    "\n",
    "        # Freeze early layers\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        n_inputs = model.classifier[6].in_features\n",
    "\n",
    "        # Add on classifier\n",
    "        model.classifier[6] = nn.Sequential(\n",
    "            nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(256, n_classes), nn.LogSoftmax(dim=1))\n",
    "\n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(pretrained=True)\n",
    "\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        n_inputs = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(256, n_classes), nn.LogSoftmax(dim=1))\n",
    "\n",
    "    # Move to gpu and parallelize\n",
    "    if train_on_gpu:\n",
    "        model = model.to('cuda')\n",
    "\n",
    "    if multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [64, 64, 224, 224]           1,792\n",
      "              ReLU-2         [64, 64, 224, 224]               0\n",
      "            Conv2d-3         [64, 64, 224, 224]          36,928\n",
      "              ReLU-4         [64, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [64, 64, 112, 112]               0\n",
      "            Conv2d-6        [64, 128, 112, 112]          73,856\n",
      "              ReLU-7        [64, 128, 112, 112]               0\n",
      "            Conv2d-8        [64, 128, 112, 112]         147,584\n",
      "              ReLU-9        [64, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [64, 128, 56, 56]               0\n",
      "           Conv2d-11          [64, 256, 56, 56]         295,168\n",
      "             ReLU-12          [64, 256, 56, 56]               0\n",
      "           Conv2d-13          [64, 256, 56, 56]         590,080\n",
      "             ReLU-14          [64, 256, 56, 56]               0\n",
      "           Conv2d-15          [64, 256, 56, 56]         590,080\n",
      "             ReLU-16          [64, 256, 56, 56]               0\n",
      "        MaxPool2d-17          [64, 256, 28, 28]               0\n",
      "           Conv2d-18          [64, 512, 28, 28]       1,180,160\n",
      "             ReLU-19          [64, 512, 28, 28]               0\n",
      "           Conv2d-20          [64, 512, 28, 28]       2,359,808\n",
      "             ReLU-21          [64, 512, 28, 28]               0\n",
      "           Conv2d-22          [64, 512, 28, 28]       2,359,808\n",
      "             ReLU-23          [64, 512, 28, 28]               0\n",
      "        MaxPool2d-24          [64, 512, 14, 14]               0\n",
      "           Conv2d-25          [64, 512, 14, 14]       2,359,808\n",
      "             ReLU-26          [64, 512, 14, 14]               0\n",
      "           Conv2d-27          [64, 512, 14, 14]       2,359,808\n",
      "             ReLU-28          [64, 512, 14, 14]               0\n",
      "           Conv2d-29          [64, 512, 14, 14]       2,359,808\n",
      "             ReLU-30          [64, 512, 14, 14]               0\n",
      "        MaxPool2d-31            [64, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-32            [64, 512, 7, 7]               0\n",
      "           Linear-33                 [64, 4096]     102,764,544\n",
      "             ReLU-34                 [64, 4096]               0\n",
      "          Dropout-35                 [64, 4096]               0\n",
      "           Linear-36                 [64, 4096]      16,781,312\n",
      "             ReLU-37                 [64, 4096]               0\n",
      "          Dropout-38                 [64, 4096]               0\n",
      "           Linear-39                  [64, 256]       1,048,832\n",
      "             ReLU-40                  [64, 256]               0\n",
      "          Dropout-41                  [64, 256]               0\n",
      "           Linear-42                    [64, 6]           1,542\n",
      "       LogSoftmax-43                    [64, 6]               0\n",
      "================================================================\n",
      "Total params: 135,310,918\n",
      "Trainable params: 1,050,374\n",
      "Non-trainable params: 134,260,544\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 36.75\n",
      "Forward/backward pass size (MB): 14001.88\n",
      "Params size (MB): 516.17\n",
      "Estimated Total Size (MB): 14554.80\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = get_pretrained_model('vgg16')\n",
    "if multi_gpu:\n",
    "    summary(\n",
    "        model.module,\n",
    "        input_size=(3, 224, 224),\n",
    "        batch_size=batch_size,\n",
    "        device='cuda')\n",
    "else:\n",
    "    summary(\n",
    "        model, input_size=(3, 224, 224), batch_size=batch_size, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'copper'),\n",
       " (1, 'mousebite'),\n",
       " (2, 'open'),\n",
       " (3, 'pin_hole'),\n",
       " (4, 'short'),\n",
       " (5, 'spur')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.class_to_idx = data['train'].class_to_idx\n",
    "model.idx_to_class = {\n",
    "    idx: class_\n",
    "    for class_, idx in model.class_to_idx.items()\n",
    "}\n",
    "\n",
    "list(model.idx_to_class.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          train_loader,\n",
    "          valid_loader,\n",
    "          save_file_name,\n",
    "          max_epochs_stop=3,\n",
    "          n_epochs=20,\n",
    "          print_every=2):\n",
    "    \"\"\"Train a PyTorch Model\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        model (PyTorch model): cnn to train\n",
    "        criterion (PyTorch loss): objective to minimize\n",
    "        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\n",
    "        train_loader (PyTorch dataloader): training dataloader to iterate through\n",
    "        valid_loader (PyTorch dataloader): validation dataloader used for early stopping\n",
    "        save_file_name (str ending in '.pt'): file path to save the model state dict\n",
    "        max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping\n",
    "        n_epochs (int): maximum number of training epochs\n",
    "        print_every (int): frequency of epochs to print training stats\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        model (PyTorch model): trained cnn with best weights\n",
    "        history (DataFrame): history of train and validation loss and accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # Early stopping intialization\n",
    "    epochs_no_improve = 0\n",
    "    valid_loss_min = np.Inf\n",
    "\n",
    "    valid_max_acc = 0\n",
    "    history = []\n",
    "\n",
    "    # Number of epochs already trained (if using loaded in model weights)\n",
    "    try:\n",
    "        print('Model has been trained for:',model.epochs, 'epochs.\\n')\n",
    "    except:\n",
    "        model.epochs = 0\n",
    "        print('Starting Training from Scratch.\\n')\n",
    "\n",
    "    overall_start = timer()\n",
    "\n",
    "    # Main loop\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # keep track of training and validation loss each epoch\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_acc = 0\n",
    "        valid_acc = 0\n",
    "\n",
    "        # Set to training\n",
    "        model.train()\n",
    "        start = timer()\n",
    "\n",
    "        # Training loop\n",
    "        for ii, (data, target) in enumerate(train_loader):\n",
    "            # Tensors to gpu\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Predicted outputs are log probabilities\n",
    "            output = model(data)\n",
    "\n",
    "            # Loss and backpropagation of gradients\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track train loss by multiplying average loss by number of examples in batch\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "\n",
    "            # Calculate accuracy by finding max log probability\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "            # Need to convert correct tensor from int to float to average\n",
    "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "            # Multiply average accuracy times the number of examples in batch\n",
    "            train_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "            # Track training progress\n",
    "            print(\n",
    "                'Epoch:',epoch, '\\t',timer() - start, 'seconds elapsed in epoch.',\n",
    "                end='\\r')\n",
    "\n",
    "        # After training loops ends, start validation\n",
    "        else:\n",
    "            model.epochs += 1\n",
    "\n",
    "            # Don't need to keep track of gradients\n",
    "            with torch.no_grad():\n",
    "                # Set to evaluation mode\n",
    "                model.eval()\n",
    "\n",
    "                # Validation loop\n",
    "                for data, target in valid_loader:\n",
    "                    # Tensors to gpu\n",
    "                    if train_on_gpu:\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                    # Forward pass\n",
    "                    output = model(data)\n",
    "\n",
    "                    # Validation loss\n",
    "                    loss = criterion(output, target)\n",
    "                    # Multiply average loss times the number of examples in batch\n",
    "                    valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                    # Calculate validation accuracy\n",
    "                    _, pred = torch.max(output, dim=1)\n",
    "                    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "                    accuracy = torch.mean(\n",
    "                        correct_tensor.type(torch.FloatTensor))\n",
    "                    # Multiply average accuracy times the number of examples\n",
    "                    valid_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "                # Calculate average losses\n",
    "                train_loss = train_loss / len(train_loader.dataset)\n",
    "                valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "\n",
    "                # Calculate average accuracy\n",
    "                train_acc = train_acc / len(train_loader.dataset)\n",
    "                valid_acc = valid_acc / len(valid_loader.dataset)\n",
    "\n",
    "                history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
    "\n",
    "                # Print training and validation results\n",
    "                if (epoch + 1) % print_every == 0:\n",
    "                    print(\n",
    "                        f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
    "                    )\n",
    "\n",
    "                    \n",
    "                    print(\n",
    "                        f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n",
    "                    )\n",
    "\n",
    "                # Save the model if validation loss decreases\n",
    "                if valid_loss < valid_loss_min:\n",
    "                    # Save model\n",
    "                    torch.save(model.state_dict(), save_file_name)\n",
    "                    # Track improvement\n",
    "                    epochs_no_improve = 0\n",
    "                    valid_loss_min = valid_loss\n",
    "                    valid_best_acc = valid_acc\n",
    "                    best_epoch = epoch\n",
    "\n",
    "                # Otherwise increment count of epochs with no improvement\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    # Trigger early stopping\n",
    "                    if epochs_no_improve >= max_epochs_stop:\n",
    "                        print(\n",
    "                            f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "                        )\n",
    "                        print('early stop')\n",
    "                        total_time = timer() - overall_start\n",
    "                        print(\n",
    "                            f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
    "                        )\n",
    "                        print(total_time,'seconds')\n",
    "                        # Load the best state dict\n",
    "                        model.load_state_dict(torch.load(save_file_name))\n",
    "                        # Attach the optimizer\n",
    "                        model.optimizer = optimizer\n",
    "\n",
    "                        # Format history\n",
    "                        history = pd.DataFrame(\n",
    "                            history,\n",
    "                            columns=[\n",
    "                                'train_loss', 'valid_loss', 'train_acc',\n",
    "                                'valid_acc'\n",
    "                            ])\n",
    "                        return model, history\n",
    "\n",
    "    # Attach the optimizer\n",
    "    model.optimizer = optimizer\n",
    "    # Record overall time and print out stats\n",
    "    total_time = timer() - overall_start\n",
    "    print(\n",
    "        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n",
    "    )\n",
    "    # Format history\n",
    "    history = pd.DataFrame(\n",
    "        history,\n",
    "        columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training from Scratch.\n",
      "\n",
      "Epoch: 1 \t 76.82211692258716 seconds elapsed in epoch..\n",
      "Epoch: 1 \tTraining Loss: 1.7626 \tValidation Loss: 1.7685\n",
      "\t\tTraining Accuracy: 21.38%\t Validation Accuracy: 20.55%\n",
      "Epoch: 3 \t 76.83750939648598 seconds elapsed in epoch..\n",
      "Epoch: 3 \tTraining Loss: 1.7457 \tValidation Loss: 1.7546\n",
      "\t\tTraining Accuracy: 23.25%\t Validation Accuracy: 22.05%\n",
      "Epoch: 5 \t 76.45040274504572 seconds elapsed in epoch..\n",
      "Epoch: 5 \tTraining Loss: 1.7321 \tValidation Loss: 1.7525\n",
      "\t\tTraining Accuracy: 23.58%\t Validation Accuracy: 21.71%\n",
      "Epoch: 7 \t 76.47631244268268 seconds elapsed in epoch..\n",
      "Epoch: 7 \tTraining Loss: 1.7237 \tValidation Loss: 1.7488\n",
      "\t\tTraining Accuracy: 24.44%\t Validation Accuracy: 22.54%\n",
      "Epoch: 9 \t 76.5898900134489 seconds elapsed in epoch...\n",
      "Epoch: 9 \tTraining Loss: 1.7203 \tValidation Loss: 1.7443\n",
      "\t\tTraining Accuracy: 24.23%\t Validation Accuracy: 22.51%\n",
      "Epoch: 11 \t 76.6827436927706 seconds elapsed in epoch...\n",
      "Epoch: 11 \tTraining Loss: 1.7132 \tValidation Loss: 1.7466\n",
      "\t\tTraining Accuracy: 24.91%\t Validation Accuracy: 22.78%\n",
      "Epoch: 13 \t 76.46260999329388 seconds elapsed in epoch..\n",
      "Epoch: 13 \tTraining Loss: 1.7101 \tValidation Loss: 1.7477\n",
      "\t\tTraining Accuracy: 25.31%\t Validation Accuracy: 22.05%\n",
      "Epoch: 15 \t 76.50335093121976 seconds elapsed in epoch..\n",
      "Epoch: 15 \tTraining Loss: 1.7063 \tValidation Loss: 1.7423\n",
      "\t\tTraining Accuracy: 25.60%\t Validation Accuracy: 22.34%\n",
      "Epoch: 17 \t 76.8130206009373 seconds elapsed in epoch...\n",
      "Epoch: 17 \tTraining Loss: 1.6948 \tValidation Loss: 1.7383\n",
      "\t\tTraining Accuracy: 26.62%\t Validation Accuracy: 22.71%\n",
      "Epoch: 19 \t 76.54625503718853 seconds elapsed in epoch..\n",
      "Epoch: 19 \tTraining Loss: 1.6905 \tValidation Loss: 1.7431\n",
      "\t\tTraining Accuracy: 26.76%\t Validation Accuracy: 22.48%\n",
      "Epoch: 21 \t 76.79493040405214 seconds elapsed in epoch..\n",
      "Epoch: 21 \tTraining Loss: 1.6927 \tValidation Loss: 1.7445\n",
      "\t\tTraining Accuracy: 26.05%\t Validation Accuracy: 22.38%\n",
      "Epoch: 22 \t 76.40951363556087 seconds elapsed in epoch..\n",
      "Early Stopping! Total epochs: 22. Best epoch: 17 with loss: 1.74 and acc: 22.54%\n",
      "early stop\n",
      "2571.91 total seconds elapsed. 111.82 seconds per epoch.\n",
      "2571.9097114903852 seconds\n"
     ]
    }
   ],
   "source": [
    "model, history = train(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    dataloaders['train'],\n",
    "    dataloaders['test'],\n",
    "    save_file_name=save_file_name,\n",
    "    max_epochs_stop=5,\n",
    "    n_epochs=30,\n",
    "    print_every=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.9\r\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
